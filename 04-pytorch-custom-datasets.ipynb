{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-06T09:38:54.954707Z","iopub.execute_input":"2023-04-06T09:38:54.955220Z","iopub.status.idle":"2023-04-06T09:38:54.981289Z","shell.execute_reply.started":"2023-04-06T09:38:54.955189Z","shell.execute_reply":"2023-04-06T09:38:54.980384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nprint(torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T09:38:54.983227Z","iopub.execute_input":"2023-04-06T09:38:54.983963Z","iopub.status.idle":"2023-04-06T09:38:57.233268Z","shell.execute_reply.started":"2023-04-06T09:38:54.983926Z","shell.execute_reply":"2023-04-06T09:38:57.232033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-04-06T09:38:57.237903Z","iopub.execute_input":"2023-04-06T09:38:57.240559Z","iopub.status.idle":"2023-04-06T09:38:57.309579Z","shell.execute_reply.started":"2023-04-06T09:38:57.240518Z","shell.execute_reply":"2023-04-06T09:38:57.308342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-04-06T09:38:57.314536Z","iopub.execute_input":"2023-04-06T09:38:57.315467Z","iopub.status.idle":"2023-04-06T09:38:58.600143Z","shell.execute_reply.started":"2023-04-06T09:38:57.315428Z","shell.execute_reply":"2023-04-06T09:38:58.598725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Get data\nFood101 datasets","metadata":{}},{"cell_type":"code","source":"import requests\nimport zipfile\nfrom pathlib import Path\n\n# Set up path to a data folder\ndata_path = Path(\"data/\")\nimage_path = data_path / \"pizza_steak_sushi\"\n\nif image_path.is_file():\n    print(f\"{image_path} is exist and skipping download...\")\nelse:\n    image_path.mkdir(parents=True, \n                     exist_ok=True)\n    \nwith open(data_path/\"pizza_steak_sushi.zip\",\"wb\") as f:\n    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n    print(\"Downloding pizza_steak_sushi.zip....\")\n    f.write(request.content)\n    \nwith zipfile.ZipFile(data_path/\"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n    print(\"Unzipping pizza_steak_sushi.zip data ....\")\n    zip_ref.extractall(image_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-06T09:38:58.602489Z","iopub.execute_input":"2023-04-06T09:38:58.602937Z","iopub.status.idle":"2023-04-06T09:39:00.756622Z","shell.execute_reply.started":"2023-04-06T09:38:58.602887Z","shell.execute_reply":"2023-04-06T09:39:00.755353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path","metadata":{"execution":{"iopub.status.busy":"2023-04-06T09:39:00.758033Z","iopub.execute_input":"2023-04-06T09:39:00.758623Z","iopub.status.idle":"2023-04-06T09:39:00.769606Z","shell.execute_reply.started":"2023-04-06T09:39:00.758584Z","shell.execute_reply":"2023-04-06T09:39:00.768209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls data/pizza_steak_sushi/test","metadata":{"execution":{"iopub.status.busy":"2023-04-06T09:39:00.771498Z","iopub.execute_input":"2023-04-06T09:39:00.772857Z","iopub.status.idle":"2023-04-06T09:39:01.931704Z","shell.execute_reply.started":"2023-04-06T09:39:00.772735Z","shell.execute_reply":"2023-04-06T09:39:01.930219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Becomming one with the data","metadata":{}},{"cell_type":"code","source":"import os \ndef walk_through_dir(dir_path):\n    \n    \"\"\"Walks through di_path returning its contents.\"\"\"\n    for dirpath, dirnames, filenames in os.walk(dir_path):\n        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","metadata":{"execution":{"iopub.status.busy":"2023-04-06T09:39:01.934074Z","iopub.execute_input":"2023-04-06T09:39:01.934463Z","iopub.status.idle":"2023-04-06T09:39:01.943715Z","shell.execute_reply.started":"2023-04-06T09:39:01.934419Z","shell.execute_reply":"2023-04-06T09:39:01.942508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"walk_through_dir(image_path)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:02:17.916317Z","iopub.execute_input":"2023-04-06T10:02:17.916601Z","iopub.status.idle":"2023-04-06T10:02:17.923882Z","shell.execute_reply.started":"2023-04-06T10:02:17.916564Z","shell.execute_reply":"2023-04-06T10:02:17.922749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup train and testing paths\ntrain_dir = image_path / \"train\"\ntest_dir = image_path / \"test\"\nprint(train_dir)\nprint(test_dir)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:08:20.642105Z","iopub.execute_input":"2023-04-06T10:08:20.643090Z","iopub.status.idle":"2023-04-06T10:08:20.649958Z","shell.execute_reply.started":"2023-04-06T10:08:20.643047Z","shell.execute_reply":"2023-04-06T10:08:20.648668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1 Visualizing and image","metadata":{}},{"cell_type":"code","source":"import random\nfrom PIL import Image\n\n# Set seed\nrandom.seed(42)\n\n# 1. Get all image paths\nimage_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n\n# print(image_path_list)\n\n# 2. Pick a random image path\nrandom_image_path = random.choice(image_path_list)\nprint(random_image_path)\n\n# 3. Get image class from path name\nimage_class = random_image_path.parent.stem\nprint(image_class)\n\n# 4. open image \nimg = Image.open(random_image_path)\n\n# 5. Print metadata\nprint(f\"Random image path : {random_image_path}\")\nprint(f\"Image class: {image_class}\")\nprint(f\"Image height: {img.height}\")\nprint(f\"Image width: {img.width}\")\nimg","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:25:27.701349Z","iopub.execute_input":"2023-04-06T10:25:27.702296Z","iopub.status.idle":"2023-04-06T10:25:27.822716Z","shell.execute_reply.started":"2023-04-06T10:25:27.702240Z","shell.execute_reply":"2023-04-06T10:25:27.821697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}